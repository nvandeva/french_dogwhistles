## after exporting the follower lists of left media accounts with xExport extension and saving them to a xlsx file (one sheet = follower list of 1 media account)

!pip install pandas openpyxl
!pip install xlsxwriter
import pandas as pd
from google.colab import files #for Colab
uploaded = files.upload()
# Read all sheets
sheets = pd.read_excel("C2-left.xlsx", sheet_name=None, engine='openpyxl')
print(sheets.keys())  # Print all sheet names

## In all the sheets of the Excel file, only keep the rows which include any location in France (city, municipality, village, country) in column E. Remove all blank rows to make it a consecutive list.
## extract all French locations from file and store them in a txt file (done using Gemini)
## filter out all the rows which don't include French locations in column E

# upload txt file in Colab
from google.colab import files
uploaded = files.upload()

# Load the Excel file and French locations list
xls = pd.ExcelFile("C2-left.xlsx")
sheet_names = xls.sheet_names

with open("french_locations_non-far-right.txt", "r", encoding="utf-8") as f:
    french_cities_set = set(line.strip() for line in f.readlines())

# Filter each sheet
filtered_dataframes = {}

for sheet in sheet_names:
    df = xls.parse(sheet)
    if 'Location' in df.columns:
        df['Location_cleaned'] = df['Location'].astype(str).str.strip()
        filtered_df = df[df['Location_cleaned'].isin(french_cities_set)]
        filtered_dataframes[sheet] = filtered_df.drop(columns=['Location_cleaned'])

# Save filtered data to a new Excel file
output_path = "C2-filtered_french_locations.xlsx"
with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
    for sheet_name, df in filtered_dataframes.items():
        df.to_excel(writer, sheet_name=sheet_name[:31], index=False)

# Download the filtered Excel file for inspection
files.download(output_path)

## Remove those with 0 tweets
## In all the sheets of both Excel files, only keep the rows which include a number higher than 0 in column H.
## Remove all blank rows to make it a consecutive list.

# Load the filtered Excel file
input_file = "C2-filtered_french_locations.xlsx"
xls = pd.ExcelFile(input_file)

# Prepare a dictionary to store cleaned dataframes
cleaned_sheets = {}

# Process each sheet
for sheet_name in xls.sheet_names:
    df = xls.parse(sheet_name)

    # Ensure there are at least 8 columns (column H is the 8th)
    if df.shape[1] >= 8:
        # Keep rows where column H is a number and greater than 0
        df = df[pd.to_numeric(df.iloc[:, 7], errors='coerce').fillna(0) > 0]

    # Drop rows that are completely blank
    df = df.dropna(how='all')

    cleaned_sheets[sheet_name] = df

# Save the cleaned data to a new Excel file
output_file = "non-far-right_filtered_followers.xlsx"
with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:
    for sheet, data in cleaned_sheets.items():
        data.to_excel(writer, sheet_name=sheet[:31], index=False)

print(f"Cleaned file saved as: {output_file}")

## Merge all sheets into one list of unique rows.
## Remove duplicates

# Load the Excel file
input_file = "non-far-right_filtered_followers.xlsx"
xls = pd.ExcelFile(input_file)

# Combine all sheets
all_data = []

for sheet_name in xls.sheet_names:
    df = xls.parse(sheet_name)
    all_data.append(df)

combined_df = pd.concat(all_data, ignore_index=True)

# Remove duplicate rows (based on all columns)
unique_df = combined_df.drop_duplicates()

# Save to a new single-sheet Excel file
output_file = "C2_left-leaning_followers.xlsx"
unique_df.to_excel(output_file, index=False)

print(f"Merged and de-duplicated file saved as: {output_file}")
files.download (output_file)
